{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pxJixfODD76"
   },
   "source": [
    "# FIT5202 Data processing for big data\n",
    "\n",
    "##  Activity: Machine Learning with Spark (Classification Using Decision Tree, Random Forest,  and Logistic Regression)\n",
    "\n",
    "Last week we learnt about basics of machine learning with Apache Spark. **``MLlib``** is Apache Spark's scalable machine learning library. Its goal is to make practical machine learning scalable and easy. At a high level, it provides tools such as:\n",
    "\n",
    "- ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering\n",
    "- Featurization: feature extraction, transformation, dimensionality reduction, and selection\n",
    "- Pipelines: tools for constructing, evaluating, and tuning ML Pipelines\n",
    "- Persistence: saving and load algorithms, models, and Pipelines\n",
    "- Utilities: linear algebra, statistics, data handling, etc.\n",
    "\n",
    "We looked into transformers, estimators and machine learning pipeline in the last weeks tutorial activity.\n",
    "\n",
    "This week we have learnt about different classification algorithms in the lecture. We will look into how to use the different popular family of classification and regression methods; Decision Trees and Random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiYZCrXJG9Cn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7feZkJb5DD77"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Bank case study: Will the client subscribe?](#one)\n",
    "* [Data Loading and Preparation](#data-preparation)\n",
    "* [Feature Engineering](#feature-engineering)\n",
    "    * [StringIndexer](#feature-engineering)\n",
    "    * [OneHotEncoder](#feature-engineering)\n",
    "    * [VectorAssembler](#feature-engineering)\n",
    "* [Pipeline API](#pipeline)\n",
    "* [Train/Test Split](#train-test)\n",
    "* [ML Classification Models](#models)\n",
    "    * [Decision Tree](#dt)\n",
    "    * [Random Forest](#rf)        \n",
    "    * [Logistic Regression](#lr)    \n",
    "* [Model Evaluation](#model-evaluation)\n",
    "    * [Confusion Matrix](#confusion-matrix)\n",
    "    * [Area Under the Curve](#roc)    \n",
    "    * [Visualizing ROC Curve](#roc-viz)\n",
    "* [Lab Tasks](#lab-task-1)\n",
    "    * [Lab Task 1](#lab-task-1)\n",
    "    * [Lab Task 2](#lab-task-2)\n",
    "    * [Lab Task 3](#lab-task-3)\n",
    "    * [Lab Task 4](#lab-task-4)\n",
    "    * [Lab Task 5](#lab-task-5)\n",
    "* [Challenge Tasks](#challenge-task)\n",
    "    * [Challenge Task 1](#challenge-task)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hptiuJSzDD78"
   },
   "source": [
    "## Bank case study: Will the client subscribe? <a class=\"anchor\" id=\"one\"></a>\n",
    "<hr/>\n",
    "\n",
    "The data was used to direct marketing campaigns of a banking institution. The marketing campaigns were based on phone calls. The classification goal is to predict whether the client will subscribe (1/0) to a term deposit.\n",
    "\n",
    "### **Attributes**\n",
    "\n",
    "1. age (numeric)\n",
    "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. education (categorical: 'primary', 'secondary', 'tertiary', 'unknown')\n",
    "5. default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6. balance : bank balance\n",
    "7. housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "8. loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "### Related with the last contact of the current campaign:\n",
    "9. contact: contact communication type (categorical: 'cellular','telephone','unknown')\n",
    "10. day: last contact day of the week (numerical: 1,2,...28,29,30)\n",
    "1. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "12. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "### Other attributes:\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success','unknown')\n",
    "\n",
    "### Output variable (desired target):\n",
    "16. deposit - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhqA_aO-T5DF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O55jsmlhRR-l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ9ufNKFDD78"
   },
   "source": [
    "<a class=\"anchor\" id=\"lab-task-1\"></a>\n",
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#FF5555\">1. Lab Task: </strong> \n",
    "\n",
    "Complete the following steps for the initial part to get the data ready for the Classification Algorithms.\n",
    "\n",
    " 1. **Loading data:** Load the <code>bank.csv</code> file using spark session\n",
    " 2. **Prepare the data :** Prepare data for machine learning and preprocess the data according to the algorithm for training. \n",
    " 3. **Feature Engineering:** Use <code>StringIndexer</code>, <code>OneHotEncoder</code> and <code>Vector Assembler</code> to transform the dataset into <em>features</em> and <em>label</em> columns. \n",
    " 4. **Pipeline API :** Assemble the above steps of transformation into a <code>Pipeline</code>. Use the pipeline to <strong>transform</strong> the data.\n",
    " 5. **Train/Test Split :** For the transformed data, create a <strong>train/test</strong> split of <strong>80%/20%</strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCXzNiagRBAB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYWZb3U9DD79"
   },
   "source": [
    "### Step 1: Data Loading and Preparation <a class=\"anchor\" name=\"data-preparation\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4vnnm9jDD79"
   },
   "source": [
    "In this step, you can do some data exploration like: \n",
    "1. See some sample data, check the schema\n",
    "2. Check the statistics of the numerical columns in the dataset\n",
    "3. Target Variable Distribution, what are the number of instances the target variable has?\n",
    "4. Check if the dataframe contains null values?\n",
    "5. Separate the numerical and non-numerical columns to apply feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9-VnoDkDD7-"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L53dtb-pDD7-"
   },
   "source": [
    "### Step 2: Feature Engineering <a class=\"anchor\" name=\"feature-engineering\"></a> \n",
    "<strong>Hint :</strong> Use all the features, separate the numerical and non-numerical features to simplify the Feature Engineering process. For the <strong style=\"color:red\"> target variable, make sure 1 is for Yes and 0 is for No</strong> while converting it to numeric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yteaS2fRDD7_"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tDLcNH2DD7_"
   },
   "source": [
    "### Step 3: Pipeline API <a class=\"anchor\" name=\"pipeline\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nckirdUIDD7_"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAgLFTqxDD7_"
   },
   "source": [
    "### Step 4: Train/Test Split <a class=\"anchor\" name=\"train-test\"></a> \n",
    "<strong>Hint : </strong> Use <code>seed</code> while splitting data to identify different sets of train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5WscJX4DD7_"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqmnYoQ8DD7_"
   },
   "source": [
    "## ML Classification Models <a class=\"anchor\" name=\"models\"></a>\n",
    "<hr />\n",
    "\n",
    "### Decision Tree <a class=\"anchor\" name=\"dt\"></a>\n",
    "Decision tree algorithms are said to be widely used because they process categorical data and are readily available in classification tasks by multiple classes. The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data). The picture below shows some components in a decistion tree.\n",
    "![image.png](attachment:image.png)\n",
    "Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that the purity of the node increases with respect to the target variable. The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.\n",
    "\n",
    "On the downside, decision trees are prone to overfitting. They can easily become over-complex which prevents them from generalizing well to the structure in the dataset. In that case, the model is likely to end up overfitting which is a serious issue in machine learning. To overcome this decision tree hyperparameters could be tuned. For a description of some parameters, refer to this\n",
    "<a href=\"https://towardsdatascience.com/hyperparameters-of-decision-trees-explained-with-visualizations-1a6ef2f67edf\" target=\"_BLANK\">link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R54S5AE2DD7_"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Extracts the number of nodes in the decision tree and the tree depth in the model and stores it in dt.\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "dtModel = #WRITE CODE : Use the fit method to train the model with the training data you created in Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTMA-ZtsDD7_"
   },
   "outputs": [],
   "source": [
    "dtPredictions = #WRITE CODE to get predictions from the test data\n",
    "#WRITE CODE to Display the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcGb_-XUDD8A"
   },
   "source": [
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#006DAE\">NOTE: </strong>\n",
    "    You can see that DecisionTree has a parameter called <code>maxDepth</code>. Discuss the significance of this parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzpyGnHdDD8A"
   },
   "source": [
    "### Random Forest <a class=\"anchor\" name=\"rf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnbBLHqrDD8A"
   },
   "outputs": [],
   "source": [
    "# WRITE CODE: Implement Random Forest Classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#WRITE CODE : Create a Random Forest Classiication model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JIY8SERDD8A"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE : get the predictions for the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnVTHeLWDD8A"
   },
   "source": [
    "### Logistic Regression <a class=\"anchor\" name=\"lr\"></a>\n",
    "*Logistic Regression* is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary/categorical outcome, we use dummy variables. You can also think of logistic regression as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as dependent variable. In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2xxjvWjDD8A"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement Logistic Regression Classifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#WRITE CODE Create an initial model using the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NztTgjY6DD8B"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE: Write the Predictions for test data and display the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E095-euKDD8B"
   },
   "source": [
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#006DAE\">NOTE: </strong>\n",
    "    Discuss various parameters used in <code>Logistic Regression</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReUFR7C8DD8B"
   },
   "source": [
    "## Model Evaluation <a class=\"anchor\" name=\"model-evaluation\"></a>\n",
    "<hr />\n",
    "Our goal is not just to build a model, it is about selecting a model which gives high accuracy on our sample data. There are different kinds of evaluation metrics, the choice of these depend on the type and implementation plan. More details on evaluation metrics for classification in Spark can be found <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html\" target=\"_BLANK\">here</a>.\n",
    "We are going to cover the following evaluation in this session:\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        Confusion Matrix\n",
    "        <ul>\n",
    "            <li>Accuracy</li>\n",
    "            <li>Precision</li>\n",
    "            <li>Recall</li>\n",
    "            <li>F1-Score</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>AUC-ROC</li>        \n",
    "    </ul>\n",
    "\n",
    "#### Accuracy\n",
    "<span style=\"color:red;font-weight:bold\">Accuracy is useful when the target class is well balanced but is not a good choice with unbalanced classes.</span> For example, if a model is designed to predict fraud from a dataset where 95% of the data points are not fraud and 5% of the data points are fraud, then a naive classifier that predicts not fraud, regardless of input, will be 95% accurate. For this reason, metrics like precision and recall are typically used because they take into account the type of error. In most applications there is some desired balance between precision and recall, which can be captured by combining the two into a single metric, called the F-measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tltBIAHrDD8B"
   },
   "source": [
    "#### Confusion Matrix <a class=\"anchor\" name=\"confusion-matrix\"></a>\n",
    "\n",
    "Confusion Matrix is a performance measurement for machine learning classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values as shown in the picture below where T/F refers to true and positive respectively, and P/N to positive and negative respectively.\n",
    "<div>\n",
    "    <!-- <div style=\"float:left;width:50%\">\n",
    "<img src=\"attachment:image.png\">\n",
    "    </div> -->\n",
    "    <div style=\"float:left;width:50%;padding-top:50px\">\n",
    "    <img src=\"https://miro.medium.com/max/1400/1*UVP_xb4F6J-M-xH3haz5Jw.png\">\n",
    "    </div>\n",
    "    <div style=\"clear:both\"></div>\n",
    "    </div>\n",
    "\n",
    "From the confusion matrix, we can obtain the following indicators.\n",
    "\n",
    "- **Recall:** Out of all the positive classes, how much we predicted correctly. It should be high as possible.\n",
    "- **Precision:** Out of all the positive classes we have predicted correctly, how many are actually positive.\n",
    "- **Accuracy:** Out of all the classes, how much we predicted correctly. It should be high as possible.\n",
    "- **F1-Score : Combining Precision and Accuracy:** It is the weighted average of Precision and Recall. It takes both <strong>False Positives</strong> and <strong>False Negative </strong> into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWSiFpSEDD8B"
   },
   "source": [
    "<a class=\"anchor\" id=\"lab-task-2\"></a>\n",
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#FF5555\">2. Lab Task: </strong>\n",
    "    Calculate the remaining <strong>False Negative and False Positive</strong> for <code>Decision Tree</code> based on the example below. Then Compute the other metrics, i.e. <strong>Accuracy</strong>, <strong>Precision</strong>, <strong>Recall</strong> and <strong>F1-Score</strong> for the DT Model.    \n",
    "    \n",
    "<strong style=\"color:orange\">NOTE:</strong>In our case we are using Yes=1 and No=0. Remember that 1 doesn't mean positive always, it will depend on how the Target variable is encoded as well.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dTyoEm3DD8B"
   },
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = dtPredictions.filter('prediction = 0 AND label = 0').count()\n",
    "TP = dtPredictions.filter('prediction = 1 AND label = 1').count()\n",
    "FN = #WRITE CODE to find the False Negative\n",
    "FP = #WRITE CODE to find the False Positive\n",
    "\n",
    "# show confusion matrix\n",
    "dtPredictions.groupBy('label', 'prediction').count().show()\n",
    "# calculate metrics by the confusion matrix\n",
    "accuracy = #WRITE CODE : formula to find accuracy\n",
    "precision = #WRITE CODE : formula to find precision\n",
    "recall = #WRITE CODE : formula to find recall\n",
    "f1 = #WRITE CODE : formula to find F1-score\n",
    "\n",
    "#WRITE CODE : Display the various metrics calculated above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCYOMQ_dDD8B"
   },
   "source": [
    "<a class=\"anchor\" id=\"lab-task-3\"></a>\n",
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#FF5555\">3. Lab Task: </strong>\n",
    "    Create a function <code>compute_metrics()</code> which takes <strong>predictions</strong> as input parameter and computes all these metrics. Use the function to compute the 4 metrics for all 3 Classification Algorithms.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU2KJeU7DD8B"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions):\n",
    "    #WRITE CODE: to calculate accuracy,precision,recall and f1 based on above example\n",
    "    return accuracy,precision,recall,f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lUMWDfJDD8C"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE : Print the accuracy,precision,recall and f1 scores for each Classification algorithm, using the function created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtHYey_MDD8C"
   },
   "source": [
    "<a class=\"anchor\" id=\"lab-task-4\"></a>\n",
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#FF5555\">4. Lab Task: </strong>\n",
    "  Present the accuracies, precision and recall of the different classification algorithms in a bar chart using <code>matplotlib</code>.  You can use the function given here:\n",
    "    <pre>\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    def plot_metrics(x,y):\n",
    "        plt.style.use('ggplot')   \n",
    "        x_pos = [i for i, _ in enumerate(x)]\n",
    "        plt.bar(x_pos, y, color='blue')\n",
    "        plt.xlabel(\"Classification Algorithms\")\n",
    "        plt.ylabel(\"AUC\")\n",
    "        plt.title(\"Accuracy of ML Classification Algorithms\")\n",
    "        plt.xticks(x_pos, x)\n",
    "        plt.show()\n",
    "    </pre>\n",
    "What do you observe about the differences in the accuracy/precision/recall/f1-scores for these different classification algorithms? How do you decide the most suitable metric? Discuss this with your tutor.   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fMJoGyfDD8C"
   },
   "source": [
    "#### Area Under the Curve (AUC-ROC) <a class=\"anchor\" name=\"roc\"></a>\n",
    "When we need to check or visualize the performance of the multi - class classification problem, we use AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification model’s performance.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div style=\"width:40%;float:left;text-align:left;\">\n",
    "<!-- <img src=\"attachment:image.png\" width=\"200px;\">\n",
    "    </div><div style=\"width:60%;float:right;text-align:justify\"> -->\n",
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s.\n",
    "    \n",
    "In the example below, we are using Spark's <code>BinaryClassificationEvaluator</code> to compute the AUC-ROC curve.\n",
    "   </div>\n",
    "   <div style=\"clear:both\"></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0muvVdflDD8C"
   },
   "source": [
    "##### Binary Classification Metrics <a class=\"anchor\" name=\"bce\"></a> \n",
    "Now let's evaluate the model using BinaryClassificationMetrics class in Spark ML. BinaryClassificationMetrics by default uses areaUnderROC as the performance metric.\n",
    "<a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target='_BLANK'>Read More</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VVPVi94DD8C"
   },
   "source": [
    "<a class=\"anchor\" id=\"lab-task-5\"></a>\n",
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#FF5555\">5. Lab Task: </strong>\n",
    "    Compute the <code>Area Under ROC</code> for the two other Algorithms based on the example below.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A_AB2gpDD8C"
   },
   "outputs": [],
   "source": [
    "# Use BinaryClassificationEvaluator to evaluate a model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model Decision Tree\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "auc_dt = evaluator.evaluate(dtPredictions)\n",
    "print(auc_dt)\n",
    "print(evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oppxGZPVDD8C"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE : area under curve for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FgU01DGDD8C"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE : area under curve for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAsDetmWDD8D"
   },
   "source": [
    "### Visualizing AUC-ROC <a class=\"anchor\" name=\"roc-viz\"></a> \n",
    "We can easily visualize the ROC curve for <strong>Logistic Regression</strong> using the <code>BinaryClassificationEvaluator</code>. The example below shows how to plot it using matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbSNM_DnDD8D"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Area Under ROC: \" + str(evaluator.evaluate(lrPredictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "\n",
    "# Plot ROC curve\n",
    "trainingSummary = lrModel.summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m2uyIjBDD8D"
   },
   "source": [
    "<div style=\"background:rgba(164,0,255,0.2);padding:10px;border-radius:4px\">\n",
    "However, for other algorithms, we need to calculate it manually. The ROC Curve is simply a line plot of <code>FPR</code> and <code>TPR</code> across all thresholds (i.e. 0-1). We can calculate <code>TPR</code> and <code>FPR</code> from the confusion matrix. However, by default, a threshold value of 0.5 is used while computing the confusion matrix. So we need a way to compute the confusion matrix for different thresholds.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR08Bi_xDD8D"
   },
   "source": [
    "##### Getting the thresholds\n",
    "We can simply use numpy <code>linspace</code> to get a list of thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__j_bTTRDD8D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.linspace(0, 1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BvmEsI7DD8D"
   },
   "source": [
    "If we look at the <code>probability</code> column of the predictions, we will see it is an <code>Array</code> with two probability values, the first one for negative class and the second one for positive class. Now we can consider the <strong>probability for positive class</strong> to decide which value is <strong>positive</strong> and which value is <strong>negative</strong>\n",
    "\n",
    "For example, if our threshold is 0.7, we can say <strong>if the positive probability is greater than 0.7, it is a positive prediction else it is a negative prediction</strong>. \n",
    "\n",
    "Here is an example for the Decision Tree Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RInRXHdgDD8D"
   },
   "outputs": [],
   "source": [
    "#User Defined Function to split the probabilities into two columns\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "to_array = F.udf(lambda v: v.toArray().tolist(), T.ArrayType(T.FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMjSdrmkDD8D"
   },
   "outputs": [],
   "source": [
    "#Splitting the probability to 2 parts using the UDF\n",
    "df = dtPredictions.withColumn('probability', to_array('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUOqW0b3DD8D"
   },
   "outputs": [],
   "source": [
    "#A new df which contains the probabilites in separate columns\n",
    "prob_df = df.select(df.probability[0].alias('negative_prob'),df.probability[1].alias('positive_prob'),'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwDqg0f7DD8D"
   },
   "source": [
    "Now, we have extracted the probabilities for positive and negative class. Now we need to create our own <code>prediction</code> column based on a threshold we are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hr28JCngDD8E"
   },
   "outputs": [],
   "source": [
    "#Here based on the threshold, the prediction column is computed\n",
    "threshold=0.7\n",
    "prob_df.withColumn('prediction',F.when(prob_df.positive_prob > threshold,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FShtcx7QDD8E"
   },
   "source": [
    "Now we can create the confusion metrics based on the new predicted class. Let's create a function to do that. The function returns the TN,TP,FN and FP values.\n",
    "\n",
    "CHALLENGE TASK: the following confusion_matrix function is slow, why is it so slow? Can you refactor it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ThkjNh6DD8E"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions):\n",
    "     # Calculate the elements of the confusion matrix\n",
    "    TN = predictions.filter('prediction = 0 AND label = 0').count()\n",
    "    TP = predictions.filter('prediction = 1 AND label = 1').count()\n",
    "    FN = predictions.filter('prediction = 0 AND label = 1').count()\n",
    "    FP = predictions.filter('prediction = 1 AND label = 0').count()\n",
    "    return TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qY9v2XgjDD8E"
   },
   "outputs": [],
   "source": [
    "#TESTING \n",
    "#for threshold 0.7, lets calculate the TN,TP,FN,FP from confusion matrix\n",
    "threshold=0.7\n",
    "test_df=prob_df.withColumn('prediction',F.when(prob_df.positive_prob > threshold,1).otherwise(0))\n",
    "tp,tn,fp,fn = confusion_matrix(prob_df)  \n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "print('TPR:',tpr,'FPR:',fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF9cDxtGDD8E"
   },
   "source": [
    "<a class=\"anchor\" id=\"challenge-task\"></a>\n",
    "<div style=\"background:rgba(164,0,255,0.2);padding:10px;border-radius:4px\"><strong style=\"color:purple\">CHALLENGE TASK: </strong>\n",
    "    Based on all the above information, create a function, which loops through all the thresholds and computes the <code>TPR</code> and <code>TFR</code> for each threshold. Store all the <code>TPR</code> and <code>TFR</code> values in separate arrays and later visualize the <strong>ROC Curve</strong> for <strong>Decision Tree</strong> and <strong>Random Forest</strong>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI-6id8bDD8E"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1kIajDbDD8E"
   },
   "source": [
    "### Congratulations on finishing this activity. See you next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtCGdr1rDD8E"
   },
   "source": [
    "## References\n",
    "\n",
    "1. https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html\n",
    "2. https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week6_Classification Algorithms.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
